{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online marketing \n",
    "Creating a model to find out whether a customer completed a online shopping or not.\n",
    "Here Iwill be using Pandas library to encode the column that mans convert words to numerical but we can also do it by using specific library like \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "labelencoder_1 = LabelEncoder()\n",
    "\n",
    "X[:,1](Or whatever matrix column you wanna change) = labelencoder_1.fit_transform(X[:, 1])\n",
    "\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "\n",
    "\n",
    "Or do what i ahve done below in this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\karti\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\karti\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\karti\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\karti\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\karti\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\karti\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\karti\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\karti\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\karti\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\karti\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\karti\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\karti\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>NumCalls</th>\n",
       "      <th>NumEmails</th>\n",
       "      <th>NumDownloads</th>\n",
       "      <th>NumEvents</th>\n",
       "      <th>NumForms</th>\n",
       "      <th>Language</th>\n",
       "      <th>Country</th>\n",
       "      <th>WebVisits</th>\n",
       "      <th>PageVisits</th>\n",
       "      <th>PriorClient</th>\n",
       "      <th>MadeAPurchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>German</td>\n",
       "      <td>Germany</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>India</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>749</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>German</td>\n",
       "      <td>Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>German</td>\n",
       "      <td>Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>751</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "      <td>India</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>752</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>753</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>German</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>753 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CustomerID  NumCalls  NumEmails  NumDownloads  NumEvents  NumForms  \\\n",
       "0             1        33         19             1          0         1   \n",
       "1             2         0          1             0          1         0   \n",
       "2             3         4          6             2          0         0   \n",
       "3             4         0         10             0          0         1   \n",
       "4             5         7          0             0          0         0   \n",
       "..          ...       ...        ...           ...        ...       ...   \n",
       "748         749         3          0             0          0         0   \n",
       "749         750         0          4             0          0         0   \n",
       "750         751        15          0             0          0         0   \n",
       "751         752         0          1             0          0         0   \n",
       "752         753        20          0             0          0         0   \n",
       "\n",
       "    Language      Country  WebVisits  PageVisits PriorClient MadeAPurchase  \n",
       "0     German      Germany       10.0         0.0         Yes            No  \n",
       "1    English          USA       61.0         0.0          No            No  \n",
       "2    Spanish       Mexico        1.0         0.0          No            No  \n",
       "3    English        India       26.0         0.0          No            No  \n",
       "4    English          USA       11.0         0.0          No           Yes  \n",
       "..       ...          ...        ...         ...         ...           ...  \n",
       "748   German       Canada        0.0         0.0          No           Yes  \n",
       "749   German       Canada        0.0         0.0          No           Yes  \n",
       "750  English        India        0.0         0.0          No           Yes  \n",
       "751  Spanish     Colombia        0.0         0.0         Yes           Yes  \n",
       "752   German  Switzerland        0.0         0.0         Yes           Yes  \n",
       "\n",
       "[753 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =  pd.read_csv('Customers2.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserting data\n",
    "While inserting the data we can directly convert data from pandas form to array by \n",
    "\n",
    "(X = data.iloc[:, 0:11].values)\n",
    "\n",
    "Or we need to just do the above code ======>  \n",
    "\n",
    "(X = data.iloc[:, 0:11].values) and (X = np.array(data_final.iloc[:, 0:18]))\n",
    "\n",
    "Both of these code will work the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX = data.iloc[:, 0:11].values\\nY = data.iloc[:, 11:].values\\nY\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  I am not using this in the actual code\n",
    "'''\n",
    "X = data.iloc[:, 0:11].values\n",
    "Y = data.iloc[:, 11:].values\n",
    "Y\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Nan\n",
    "In the data given there are a lot of Nan included. Even a single Nan in your data set can ruin your model. So it is very important to remove this Nan from the data set. This code written below will remove Nan from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   \\nt,k = X.shape\\nfor x in range(t):\\n    for y in range(k):\\n        if str(X[x, y]) == \\'nan\\':\\n            X = np.delete(X, x, 0)\\n            Y = np.delete(Y, x, 0)\\n            print(\"NAN waali row removed\")  \\n            print(x)\\n            break\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code removes Nan. But we are not going to use it directly. We will implement it in 2 steps. 1st all the rows\n",
    "# which has Nan will get recognized and in the 2nd step will remove them.\n",
    "   \n",
    "    \n",
    "# I am not using this code in the model. Read the statement above. I have re implemented the details below after a while(Converting all the text data to numbers) \n",
    "'''   \n",
    "t,k = X.shape\n",
    "for x in range(t):\n",
    "    for y in range(k):\n",
    "        if str(X[x, y]) == 'nan':\n",
    "            X = np.delete(X, x, 0)\n",
    "            Y = np.delete(Y, x, 0)\n",
    "            print(\"NAN waali row removed\")  \n",
    "            print(x)\n",
    "            break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label & One Hot Encode using Pandas\n",
    "\n",
    "Datas can be Label encoded and one hot encoded using the code written in the 1st cell of the notebook. But even using the pandas library we can label encode the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0       No\\n1       No\\n2       No\\n3       No\\n4      Yes\\n      ... \\n748    Yes\\n749    Yes\\n750    Yes\\n751    Yes\\n752    Yes\\nName: MadeAPurchase, Length: 753, dtype: object_No</th>\n",
       "      <th>0       No\\n1       No\\n2       No\\n3       No\\n4      Yes\\n      ... \\n748    Yes\\n749    Yes\\n750    Yes\\n751    Yes\\n752    Yes\\nName: MadeAPurchase, Length: 753, dtype: object_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>753 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0       No\\n1       No\\n2       No\\n3       No\\n4      Yes\\n      ... \\n748    Yes\\n749    Yes\\n750    Yes\\n751    Yes\\n752    Yes\\nName: MadeAPurchase, Length: 753, dtype: object_No  \\\n",
       "0                                                    0                                                                                                                                        \n",
       "1                                                    1                                                                                                                                        \n",
       "2                                                    1                                                                                                                                        \n",
       "3                                                    1                                                                                                                                        \n",
       "4                                                    1                                                                                                                                        \n",
       "..                                                 ...                                                                                                                                        \n",
       "748                                                  1                                                                                                                                        \n",
       "749                                                  1                                                                                                                                        \n",
       "750                                                  1                                                                                                                                        \n",
       "751                                                  0                                                                                                                                        \n",
       "752                                                  0                                                                                                                                        \n",
       "\n",
       "     0       No\\n1       No\\n2       No\\n3       No\\n4      Yes\\n      ... \\n748    Yes\\n749    Yes\\n750    Yes\\n751    Yes\\n752    Yes\\nName: MadeAPurchase, Length: 753, dtype: object_Yes  \n",
       "0                                                    1                                                                                                                                        \n",
       "1                                                    0                                                                                                                                        \n",
       "2                                                    0                                                                                                                                        \n",
       "3                                                    0                                                                                                                                        \n",
       "4                                                    0                                                                                                                                        \n",
       "..                                                 ...                                                                                                                                        \n",
       "748                                                  0                                                                                                                                        \n",
       "749                                                  0                                                                                                                                        \n",
       "750                                                  0                                                                                                                                        \n",
       "751                                                  1                                                                                                                                        \n",
       "752                                                  1                                                                                                                                        \n",
       "\n",
       "[753 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This way we directly can make one hot encoder in 'country' column of the table. But the problem with this tye of the code is \n",
    "# that here all the countries are alloted with a number even if out of all the countries only top 5 are most occuring and rest\n",
    "# are near about 0. Let say there are about 100 countries, So about 100 columns would be made and to distinguish between them \n",
    "# we will have a vector = [0,0,0,0,...0,1,0,0,0] where (1) appears only once in the vector corresponding to the country where\n",
    "# it belongs. So in these condition we make just 5-10 columns with maximum occurence adn the rest of the countries will be\n",
    "# adjusted in just one column (\"Others\") OR A NULL VECTOR [0,0,0,0,0,0....00]. So to apply One hot encoder in best 5 country \n",
    "# we need to do something else. \n",
    "\n",
    "\n",
    "# BUt we can do apply it for YES and NO Options (That means in the Client and Made A Purchase colums). As they only hav two columns\n",
    "\n",
    "dummies = pd.get_dummies(data.PriorClient, data.MadeAPurchase)\n",
    "dummies    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nt,k = X.shape\\nfor x in range(t):\\n    for y in range(k):\\n            \\n        if str(X[x, y]) == \\'nan\\':\\n            print(\"NAN row removed\")  \\n            print(x)\\n            \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The above mentioned code will be implemented this way in two steps(look in this cell and the next).\n",
    "\n",
    "# This cell recognizes the Nan containing Rows\n",
    "\n",
    "'''\n",
    "t,k = X.shape\n",
    "for x in range(t):\n",
    "    for y in range(k):\n",
    "            \n",
    "        if str(X[x, y]) == 'nan':\n",
    "            print(\"NAN row removed\")  \n",
    "            print(x)\n",
    "            \n",
    "'''       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX = np.delete(X, [54, 55, 56, 57, 58, 59, 60], 0)\\nY = np.delete(Y, [54, 55, 56, 57, 58, 59, 60], 0)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code deletes the Nan containg rows\n",
    "'''\n",
    "X = np.delete(X, [54, 55, 56, 57, 58, 59, 60], 0)\n",
    "Y = np.delete(Y, [54, 55, 56, 57, 58, 59, 60], 0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the way to rename few headings of the of the data inserted\n",
    "\n",
    "\n",
    "# dummies.rename(columns = {'0 No\\n1 No\\n2 No\\n3 No\\n4 Yes\\n ... \\n748 Yes\\n749 Yes\\n750 Yes\\n751 Yes\\n752 Yes\\nName: MadeAPurchase, Length: 753, dtype: object_No' : 'PriorClient',\n",
    "#                          '0 No\\n1 No\\n2 No\\n3 No\\n4 Yes\\n ... \\n748 Yes\\n749 Yes\\n750 Yes\\n751 Yes\\n752 Yes\\nName: MadeAPurchase, Length: 753, dtype: object_Yes' : 'MadeAPurchase'\n",
    "#                         }, inplace = True)\n",
    "# dummies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prior_Client</th>\n",
       "      <th>Made_A_Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>753 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prior_Client  Made_A_Purchase\n",
       "0               0                1\n",
       "1               1                0\n",
       "2               1                0\n",
       "3               1                0\n",
       "4               1                0\n",
       "..            ...              ...\n",
       "748             1                0\n",
       "749             1                0\n",
       "750             1                0\n",
       "751             0                1\n",
       "752             0                1\n",
       "\n",
       "[753 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the way to change the name of all the columns of the inserted data. \n",
    "\n",
    "column_name = ['Prior_Client', 'Made_A_Purchase']\n",
    "dummies.columns = column_name\n",
    "dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Pandas to One Hot Encode the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English       384\n",
       "German         96\n",
       "Spanish        75\n",
       "Japanese       72\n",
       "Chinese        27\n",
       "Portuguese     15\n",
       "Italian        15\n",
       "Dutch          12\n",
       "Finnish         9\n",
       "French          9\n",
       "Name: Language, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just checking out the 10 Most Occured Language in the data set\n",
    "\n",
    "data.Language.value_counts().sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USA         180\n",
       "Canada      151\n",
       "Japan        72\n",
       "France       43\n",
       "China        39\n",
       "Mexico       36\n",
       "Spain        27\n",
       "Colombia     27\n",
       "India        24\n",
       "Brazil       24\n",
       "Name: Country, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just checking out the 10 Most Occured Country in the data set\n",
    "\n",
    "data.Country.value_counts().sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['English', 'German', 'Spanish', 'Japanese', 'Chinese']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At the end of the code above you need to add the \".index\" word. \n",
    "# If you won't do that then the nmber of times this language is used will append in the list (as numerical data)\n",
    "# list like this would have been the result = \" [384, 96, 75, 72, 27] \" instaed of the country\n",
    "\n",
    "Top5_Language = [x for x in data.Language.value_counts().sort_values(ascending = False).head(5).index]\n",
    "Top5_Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['USA', 'Canada', 'Japan', 'France', 'China']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An array has be made for the 5 most occured countries in the data set\n",
    "\n",
    "Top5_Country = [x for x in data.Country.value_counts().sort_values(ascending = False).head(5).index]\n",
    "Top5_Country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here comes the actual code for applying One hot encode to the data set\n",
    "\n",
    "When you will be applying this code you donot need to merge it again with the data set because it will aleady be added to the original data set. So the Countries (Encoded) and Language(Encoded) is already added.\n",
    "\n",
    "But if you are using the \".get_dummies\" of pandas then you need to apply merging of data with the original data set. I have done this merging below only for the last two column(PrioCients and MadeAPurchase) of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>English</th>\n",
       "      <th>German</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Japanese</th>\n",
       "      <th>Chinese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>German</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>German</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>German</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>753 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Language  English  German  Spanish  Japanese  Chinese\n",
       "0     German        0       1        0         0        0\n",
       "1    English        1       0        0         0        0\n",
       "2    Spanish        0       0        1         0        0\n",
       "3    English        1       0        0         0        0\n",
       "4    English        1       0        0         0        0\n",
       "..       ...      ...     ...      ...       ...      ...\n",
       "748   German        0       1        0         0        0\n",
       "749   German        0       1        0         0        0\n",
       "750  English        1       0        0         0        0\n",
       "751  Spanish        0       0        1         0        0\n",
       "752   German        0       1        0         0        0\n",
       "\n",
       "[753 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for label_1 in Top5_Language:\n",
    "    data[label_1] = np.where(data['Language'] == label_1, 1, 0)\n",
    " \n",
    "Language_data = data[['Language'] + Top5_Language]\n",
    "Language_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>USA</th>\n",
       "      <th>Canada</th>\n",
       "      <th>Japan</th>\n",
       "      <th>France</th>\n",
       "      <th>China</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>Canada</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>Canada</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>India</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>753 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country  USA  Canada  Japan  France  China\n",
       "0        Germany    0       0      0       0      0\n",
       "1            USA    1       0      0       0      0\n",
       "2         Mexico    0       0      0       0      0\n",
       "3          India    0       0      0       0      0\n",
       "4            USA    1       0      0       0      0\n",
       "..           ...  ...     ...    ...     ...    ...\n",
       "748       Canada    0       1      0       0      0\n",
       "749       Canada    0       1      0       0      0\n",
       "750        India    0       0      0       0      0\n",
       "751     Colombia    0       0      0       0      0\n",
       "752  Switzerland    0       0      0       0      0\n",
       "\n",
       "[753 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for label_2 in Top5_Country:\n",
    "    data[label_2] = np.where(data['Country'] == label_2, 1, 0)\n",
    " \n",
    "Country_data = data[['Country'] + Top5_Country]\n",
    "Country_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          Country  USA  Canada  Japan  France  China\n",
       "0        Germany    0       0      0       0      0\n",
       "1            USA    1       0      0       0      0\n",
       "2         Mexico    0       0      0       0      0\n",
       "3          India    0       0      0       0      0\n",
       "4            USA    1       0      0       0      0\n",
       "..           ...  ...     ...    ...     ...    ...\n",
       "748       Canada    0       1      0       0      0\n",
       "749       Canada    0       1      0       0      0\n",
       "750        India    0       0      0       0      0\n",
       "751     Colombia    0       0      0       0      0\n",
       "752  Switzerland    0       0      0       0      0\n",
       "\n",
       "[753 rows x 6 columns]>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Country'] + Top5_Country].head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>NumCalls</th>\n",
       "      <th>NumEmails</th>\n",
       "      <th>NumDownloads</th>\n",
       "      <th>NumEvents</th>\n",
       "      <th>NumForms</th>\n",
       "      <th>Language</th>\n",
       "      <th>Country</th>\n",
       "      <th>WebVisits</th>\n",
       "      <th>PageVisits</th>\n",
       "      <th>...</th>\n",
       "      <th>English</th>\n",
       "      <th>German</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Japanese</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>USA</th>\n",
       "      <th>Canada</th>\n",
       "      <th>Japan</th>\n",
       "      <th>France</th>\n",
       "      <th>China</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>German</td>\n",
       "      <td>Germany</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>India</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>749</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>German</td>\n",
       "      <td>Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>German</td>\n",
       "      <td>Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>751</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "      <td>India</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>752</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>753</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>German</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>753 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CustomerID  NumCalls  NumEmails  NumDownloads  NumEvents  NumForms  \\\n",
       "0             1        33         19             1          0         1   \n",
       "1             2         0          1             0          1         0   \n",
       "2             3         4          6             2          0         0   \n",
       "3             4         0         10             0          0         1   \n",
       "4             5         7          0             0          0         0   \n",
       "..          ...       ...        ...           ...        ...       ...   \n",
       "748         749         3          0             0          0         0   \n",
       "749         750         0          4             0          0         0   \n",
       "750         751        15          0             0          0         0   \n",
       "751         752         0          1             0          0         0   \n",
       "752         753        20          0             0          0         0   \n",
       "\n",
       "    Language      Country  WebVisits  PageVisits  ... English German  Spanish  \\\n",
       "0     German      Germany       10.0         0.0  ...       0      1        0   \n",
       "1    English          USA       61.0         0.0  ...       1      0        0   \n",
       "2    Spanish       Mexico        1.0         0.0  ...       0      0        1   \n",
       "3    English        India       26.0         0.0  ...       1      0        0   \n",
       "4    English          USA       11.0         0.0  ...       1      0        0   \n",
       "..       ...          ...        ...         ...  ...     ...    ...      ...   \n",
       "748   German       Canada        0.0         0.0  ...       0      1        0   \n",
       "749   German       Canada        0.0         0.0  ...       0      1        0   \n",
       "750  English        India        0.0         0.0  ...       1      0        0   \n",
       "751  Spanish     Colombia        0.0         0.0  ...       0      0        1   \n",
       "752   German  Switzerland        0.0         0.0  ...       0      1        0   \n",
       "\n",
       "     Japanese  Chinese  USA  Canada  Japan  France  China  \n",
       "0           0        0    0       0      0       0      0  \n",
       "1           0        0    1       0      0       0      0  \n",
       "2           0        0    0       0      0       0      0  \n",
       "3           0        0    0       0      0       0      0  \n",
       "4           0        0    1       0      0       0      0  \n",
       "..        ...      ...  ...     ...    ...     ...    ...  \n",
       "748         0        0    0       1      0       0      0  \n",
       "749         0        0    0       1      0       0      0  \n",
       "750         0        0    0       0      0       0      0  \n",
       "751         0        0    0       0      0       0      0  \n",
       "752         0        0    0       0      0       0      0  \n",
       "\n",
       "[753 rows x 22 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Already are data set is containing the columns of the Countries(One Hot Encoded) and \n",
    "# Language(One Hot Encoded) because of the code above. So we just need to remove the original columns of Language and Country\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>NumCalls</th>\n",
       "      <th>NumEmails</th>\n",
       "      <th>NumDownloads</th>\n",
       "      <th>NumEvents</th>\n",
       "      <th>NumForms</th>\n",
       "      <th>Language</th>\n",
       "      <th>Country</th>\n",
       "      <th>WebVisits</th>\n",
       "      <th>PageVisits</th>\n",
       "      <th>...</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Japanese</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>USA</th>\n",
       "      <th>Canada</th>\n",
       "      <th>Japan</th>\n",
       "      <th>France</th>\n",
       "      <th>China</th>\n",
       "      <th>Prior_Client</th>\n",
       "      <th>Made_A_Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>German</td>\n",
       "      <td>Germany</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>India</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>749</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>German</td>\n",
       "      <td>Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>German</td>\n",
       "      <td>Canada</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>751</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "      <td>India</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>752</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>753</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>German</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>753 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CustomerID  NumCalls  NumEmails  NumDownloads  NumEvents  NumForms  \\\n",
       "0             1        33         19             1          0         1   \n",
       "1             2         0          1             0          1         0   \n",
       "2             3         4          6             2          0         0   \n",
       "3             4         0         10             0          0         1   \n",
       "4             5         7          0             0          0         0   \n",
       "..          ...       ...        ...           ...        ...       ...   \n",
       "748         749         3          0             0          0         0   \n",
       "749         750         0          4             0          0         0   \n",
       "750         751        15          0             0          0         0   \n",
       "751         752         0          1             0          0         0   \n",
       "752         753        20          0             0          0         0   \n",
       "\n",
       "    Language      Country  WebVisits  PageVisits  ... Spanish Japanese  \\\n",
       "0     German      Germany       10.0         0.0  ...       0        0   \n",
       "1    English          USA       61.0         0.0  ...       0        0   \n",
       "2    Spanish       Mexico        1.0         0.0  ...       1        0   \n",
       "3    English        India       26.0         0.0  ...       0        0   \n",
       "4    English          USA       11.0         0.0  ...       0        0   \n",
       "..       ...          ...        ...         ...  ...     ...      ...   \n",
       "748   German       Canada        0.0         0.0  ...       0        0   \n",
       "749   German       Canada        0.0         0.0  ...       0        0   \n",
       "750  English        India        0.0         0.0  ...       0        0   \n",
       "751  Spanish     Colombia        0.0         0.0  ...       1        0   \n",
       "752   German  Switzerland        0.0         0.0  ...       0        0   \n",
       "\n",
       "     Chinese  USA  Canada  Japan  France  China  Prior_Client  Made_A_Purchase  \n",
       "0          0    0       0      0       0      0             0                1  \n",
       "1          0    1       0      0       0      0             1                0  \n",
       "2          0    0       0      0       0      0             1                0  \n",
       "3          0    0       0      0       0      0             1                0  \n",
       "4          0    1       0      0       0      0             1                0  \n",
       "..       ...  ...     ...    ...     ...    ...           ...              ...  \n",
       "748        0    0       1      0       0      0             1                0  \n",
       "749        0    0       1      0       0      0             1                0  \n",
       "750        0    0       0      0       0      0             1                0  \n",
       "751        0    0       0      0       0      0             0                1  \n",
       "752        0    0       0      0       0      0             0                1  \n",
       "\n",
       "[753 rows x 24 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code merges the original data with the label encoded data set (done by Pandas). \n",
    "# Use this code only when you are using the \"get_dummies\" code written above. Otherwise you need not execute this code\n",
    "# AS MENTIONED ABOVE IN THE HEADING. This code merges the last two column of PriorClient and MadeAPurchase (Encoded) with the data set. \n",
    "\n",
    "data_set = pd.concat([data, dummies], axis = 'columns')\n",
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumCalls</th>\n",
       "      <th>NumEmails</th>\n",
       "      <th>NumDownloads</th>\n",
       "      <th>NumEvents</th>\n",
       "      <th>NumForms</th>\n",
       "      <th>WebVisits</th>\n",
       "      <th>PageVisits</th>\n",
       "      <th>English</th>\n",
       "      <th>German</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Japanese</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>USA</th>\n",
       "      <th>Canada</th>\n",
       "      <th>Japan</th>\n",
       "      <th>France</th>\n",
       "      <th>China</th>\n",
       "      <th>Prior_Client</th>\n",
       "      <th>Made_A_Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>753 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NumCalls  NumEmails  NumDownloads  NumEvents  NumForms  WebVisits  \\\n",
       "0          33         19             1          0         1       10.0   \n",
       "1           0          1             0          1         0       61.0   \n",
       "2           4          6             2          0         0        1.0   \n",
       "3           0         10             0          0         1       26.0   \n",
       "4           7          0             0          0         0       11.0   \n",
       "..        ...        ...           ...        ...       ...        ...   \n",
       "748         3          0             0          0         0        0.0   \n",
       "749         0          4             0          0         0        0.0   \n",
       "750        15          0             0          0         0        0.0   \n",
       "751         0          1             0          0         0        0.0   \n",
       "752        20          0             0          0         0        0.0   \n",
       "\n",
       "     PageVisits  English  German  Spanish  Japanese  Chinese  USA  Canada  \\\n",
       "0           0.0        0       1        0         0        0    0       0   \n",
       "1           0.0        1       0        0         0        0    1       0   \n",
       "2           0.0        0       0        1         0        0    0       0   \n",
       "3           0.0        1       0        0         0        0    0       0   \n",
       "4           0.0        1       0        0         0        0    1       0   \n",
       "..          ...      ...     ...      ...       ...      ...  ...     ...   \n",
       "748         0.0        0       1        0         0        0    0       1   \n",
       "749         0.0        0       1        0         0        0    0       1   \n",
       "750         0.0        1       0        0         0        0    0       0   \n",
       "751         0.0        0       0        1         0        0    0       0   \n",
       "752         0.0        0       1        0         0        0    0       0   \n",
       "\n",
       "     Japan  France  China  Prior_Client  Made_A_Purchase  \n",
       "0        0       0      0             0                1  \n",
       "1        0       0      0             1                0  \n",
       "2        0       0      0             1                0  \n",
       "3        0       0      0             1                0  \n",
       "4        0       0      0             1                0  \n",
       "..     ...     ...    ...           ...              ...  \n",
       "748      0       0      0             1                0  \n",
       "749      0       0      0             1                0  \n",
       "750      0       0      0             1                0  \n",
       "751      0       0      0             0                1  \n",
       "752      0       0      0             0                1  \n",
       "\n",
       "[753 rows x 19 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we need to drop out the columns that are NOT USEFUL in our training set and \n",
    "# other columns for which we have already applied One hot encoder.\n",
    "\n",
    "data_final = data_set.drop(['CustomerID', 'Language', 'Country', 'PriorClient', 'MadeAPurchase'], axis = 'columns')\n",
    "data_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Converting to Array\n",
    "\n",
    "As mentioned before this is another way to convert pandas dat to array. And i have actually used this code in my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data_final.iloc[:, 0:18])\n",
    "Y = np.array(data_final['Made_A_Purchase'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nan\n",
    "\n",
    "This code to assert if a Nan is there in the data set or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(753, 18)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert np.any(np.isnan(X))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-c12f4a25018c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_new' is not defined"
     ]
    }
   ],
   "source": [
    "assert not np.any(np.isnan(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAN row removed\n",
      "54\n",
      "NAN row removed\n",
      "54\n",
      "NAN row removed\n",
      "55\n",
      "NAN row removed\n",
      "55\n",
      "NAN row removed\n",
      "56\n",
      "NAN row removed\n",
      "56\n",
      "NAN row removed\n",
      "57\n",
      "NAN row removed\n",
      "57\n",
      "NAN row removed\n",
      "58\n",
      "NAN row removed\n",
      "58\n",
      "NAN row removed\n",
      "59\n",
      "NAN row removed\n",
      "59\n",
      "NAN row removed\n",
      "60\n",
      "NAN row removed\n",
      "60\n",
      "NAN row removed\n",
      "61\n",
      "NAN row removed\n",
      "61\n",
      "NAN row removed\n",
      "62\n",
      "NAN row removed\n",
      "62\n",
      "NAN row removed\n",
      "63\n",
      "NAN row removed\n",
      "63\n",
      "NAN row removed\n",
      "64\n",
      "NAN row removed\n",
      "64\n",
      "NAN row removed\n",
      "65\n",
      "NAN row removed\n",
      "65\n",
      "NAN row removed\n",
      "66\n",
      "NAN row removed\n",
      "66\n",
      "NAN row removed\n",
      "67\n",
      "NAN row removed\n",
      "67\n"
     ]
    }
   ],
   "source": [
    "# This is the code to find out exactly which rows are having the Nan in the data set\n",
    "\n",
    "# I am actually using this code inthe data set\n",
    "\n",
    "t,k = X.shape\n",
    "for x in range(t):\n",
    "    for y in range(k):\n",
    "            \n",
    "        if str(X[x, y]) == 'nan':\n",
    "            \n",
    "            print(\"NAN row removed\")  \n",
    "            print(x)\n",
    "            \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As mentioned previously I am using this line of code to delete the rows that has Nan\n",
    "\n",
    "# I am using this code in my model\n",
    "\n",
    "X = np.delete(X, [54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67], 0)\n",
    "Y = np.delete(Y, [54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAN row removed\n",
      "54\n",
      "NAN row removed\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "# Checking it again, If at all any Nan \n",
    "\n",
    "t,k = X.shape\n",
    "for x in range(t):\n",
    "    for y in range(k):\n",
    "            \n",
    "        if str(X[x, y]) == 'nan':\n",
    "            \n",
    "            print(\"NAN row removed\")  \n",
    "            print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.delete(X, 54, 0)\n",
    "Y = np.delete(Y, 54, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checked again\n",
    "# Appears(In the Output) as if there is no Nan left now\n",
    "\n",
    "t,k = X.shape\n",
    "for x in range(t):\n",
    "    for y in range(k):\n",
    "            \n",
    "        if str(X[x, y]) == 'nan':\n",
    "            \n",
    "            print(\"NAN waali row removed\")  \n",
    "            print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(739, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = Y.reshape(739, 1)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(739, 18)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Ingredients\n",
    "\n",
    "Here I am starting the code required for making the model. I am not making Heading for each code block of the model for that you can se the previous loaded model of Spam filtering. There i have coded each of the under a seperate heading.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_L_layer(node_vector):\n",
    "       \n",
    "    parameters = {}\n",
    "    L = len(node_vector)            \n",
    "\n",
    "    for l in range(1, L):\n",
    "        \n",
    "        parameters['W' + str(l)] = np.random.randn(node_vector[l], node_vector[l-1]) * 0.01\n",
    "        parameters['b' + str(l)] = np.zeros(shape = (node_vector[l], 1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    return A    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    A = np.maximum(Z, 0)\n",
    "    return A    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_derivative(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(Z):\n",
    "    A = Z * (1-Z)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propogation(parameters, X):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2              \n",
    "        \n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "     \n",
    "        Z = np.dot(parameters[\"W\" + str(l)], A_prev) + parameters[\"b\" + str(l)]\n",
    "        linear_cache = (A_prev, parameters[\"W\" + str(l)], parameters[\"b\" + str(l)])\n",
    "        A = relu(Z)\n",
    "    \n",
    "        cache = (linear_cache)\n",
    "        caches.append(cache)\n",
    "        \n",
    "    Z_hat = np.dot(parameters[\"W\" + str(L)], A) + parameters[\"b\" + str(L)]\n",
    "    linear_cache = (A, parameters[\"W\" + str(L)], parameters[\"b\" + str(L)])\n",
    "    A_hat = sigmoid(Z_hat)\n",
    "    cache = (linear_cache)\n",
    "    caches.append(cache)\n",
    "    \n",
    "            \n",
    "    return A_hat, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A_hat, Y, epsilon):\n",
    "    m = Y.shape[1]\n",
    "\n",
    "    cost = (-1 / m) * np.sum(np.multiply(Y, np.log(A_hat + epsilon)) + np.multiply(1 - Y, np.log(1 - A_hat + epsilon)))\n",
    "    cost = np.squeeze(cost)     \n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop_1(dA, cache, AL, Y_hat, activation):\n",
    "    A_prev, W, b = cache\n",
    "    \n",
    "  \n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        \n",
    "        dZ = dA * relu_derivative(np.dot(W, A_prev) + b)  \n",
    "        dW = (1/m) * np.dot(dZ, A_prev.T)  \n",
    "        db = (1/m) * np.sum(dZ, axis = 1, keepdims = True)\n",
    "        dA_prev = np.dot(W.T, dZ) \n",
    "                \n",
    "    elif activation == \"sigmoid\":\n",
    "        \n",
    "        # dZ = AL - Y_hat     # This line is for linear regression\n",
    "        dZ = dA * sigmoid_derivative(AL) \n",
    "        dW = (1/m) * np.dot(dZ, A_prev.T)\n",
    "        db = (1/m) * np.sum(dZ, axis = 1, keepdims = True)\n",
    "        dA_prev = np.dot(W.T, dZ)\n",
    "            \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propogation(A_hat, Y, caches):\n",
    "    grads = {}\n",
    "    L = len(caches) \n",
    "    m = A_hat.shape[1]\n",
    "    Y = Y.reshape(A_hat.shape) \n",
    "    \n",
    "    dAL = - (np.divide(Y, A_hat) - np.divide(1 - Y, 1 - A_hat))\n",
    "    \n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = backward_prop_1(dAL, current_cache, A_hat, Y, activation = \"sigmoid\")\n",
    "    \n",
    "    # Ranges from l-2 to 0\n",
    "    for l in reversed(range(L-1)):\n",
    "        \n",
    "        current_cache = caches[l]\n",
    "        \n",
    "        dA_prev_temp, dW_temp, db_temp = backward_prop_1(grads[\"dA\" + str(l+1)], current_cache, A_hat, Y, activation = \"relu\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "       \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_adam(parameters) :\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural networks\n",
    "    v = {}\n",
    "    s = {}\n",
    "    \n",
    "    for l in range(L):\n",
    "    \n",
    "        v[\"dW\" + str(l+1)] = np.zeros(parameters[\"W\" + str(l+1)].shape)\n",
    "        v[\"db\" + str(l+1)] = np.zeros(parameters[\"b\" + str(l+1)].shape)\n",
    "        s[\"dW\" + str(l+1)] = np.zeros(parameters[\"W\" + str(l+1)].shape)\n",
    "        s[\"db\" + str(l+1)] = np.zeros(parameters[\"b\" + str(l+1)].shape)\n",
    "        \n",
    "    return v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0.01,\n",
    "                                beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):\n",
    "   \n",
    "    \n",
    "    L = len(parameters) // 2                 \n",
    "    v_corrected = {}                         \n",
    "    s_corrected = {}                         \n",
    "    \n",
    "    # Perform Adam update on all parameters\n",
    "    for l in range(L):\n",
    "       \n",
    "        v[\"dW\" + str(l+1)] = (v[\"dW\" + str(l+1)] * beta1) + ((1-beta1) * grads[\"dW\" + str(l+1)])\n",
    "        v[\"db\" + str(l+1)] = (v[\"db\" + str(l+1)] * beta1) + ((1-beta1) * grads[\"db\" + str(l+1)])\n",
    "        \n",
    "        # Compute bias-corrected first moment estimate. Inputs: \"v, beta1, t\". Output: \"v_corrected\".\n",
    "        \n",
    "        v_corrected[\"dW\" + str(l+1)] = v[\"dW\" + str(l+1)] / (1-np.power(beta1,t)) \n",
    "        v_corrected[\"db\" + str(l+1)] = v[\"db\" + str(l+1)] / (1-np.power(beta1,t))\n",
    "        \n",
    "\n",
    "        # Moving average of the squared gradients. Inputs: \"s, grads, beta2\". Output: \"s\".\n",
    "        \n",
    "        s[\"dW\" + str(l+1)] = (s[\"dW\" + str(l+1)] * beta2) + ((1-beta2) * (grads[\"dW\" + str(l+1)] ** 2))\n",
    "        s[\"db\" + str(l+1)] = (s[\"db\" + str(l+1)] * beta2) + ((1-beta2) * (grads[\"db\" + str(l+1)] ** 2))\n",
    "        \n",
    "        # Compute bias-corrected second raw moment estimate. Inputs: \"s, beta2, t\". Output: \"s_corrected\".\n",
    "        \n",
    "        s_corrected[\"dW\" + str(l+1)] = s[\"dW\" + str(l+1)] / (1-np.power(beta2,t))\n",
    "        s_corrected[\"db\" + str(l+1)] = s[\"db\" + str(l+1)] / (1-np.power(beta2,t))\n",
    "        \n",
    "        # Update parameters. Inputs: \"parameters, learning_rate, v_corrected, s_corrected, epsilon\". Output: \"parameters\".\n",
    "        \n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - (learning_rate * (v_corrected[\"dW\" + str(l+1)] / np.sqrt(s_corrected[\"dW\" + str(l+1)] + epsilon))) \n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - (learning_rate * (v_corrected[\"db\" + str(l+1)] / np.sqrt(s_corrected[\"db\" + str(l+1)] + epsilon)))\n",
    "        \n",
    "\n",
    "    return parameters, v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, node_vector,beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, learning_rate = 0.009, num_iterations = 2500, print_cost=True):\n",
    "   \n",
    "    costs = []\n",
    "    t = 0\n",
    "    \n",
    "        # Parameters initialization.\n",
    "    \n",
    "    parameters = initialize_parameters_L_layer(node_vector)\n",
    "    v, s = initialize_adam(parameters)\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation\n",
    "    \n",
    "        A_hat, caches = forward_propogation(parameters, X)\n",
    "              \n",
    "        # Compute cost.\n",
    "      \n",
    "        cost = compute_cost(A_hat, Y, epsilon)\n",
    "          \n",
    "        # Backward propagation.\n",
    "      \n",
    "        grads = back_propogation(A_hat, Y, caches)\n",
    "      \n",
    " \n",
    "        # Update parameters.\n",
    "      \n",
    "        #parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        t = t + 1 # Adam counter\n",
    "        parameters, v, s = update_parameters_with_adam(parameters, grads, v, s,\n",
    "                                                               t, learning_rate, beta1, beta2,  epsilon)\n",
    "                        \n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters, A_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data set\n",
    "\n",
    "Here I am splitting the data set into X_train, Y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_data_set = X.T\n",
    "Y = Y.T \n",
    "X_train = X_data_set[:, :678]\n",
    "\n",
    "X_test = X_data_set[:, 678:]\n",
    "Y_train = Y[:, :678]\n",
    "\n",
    "Y_test = Y[:, 678:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing the code\n",
    "\n",
    "Any valu or say numerical may be 450 and other may be 0 or 1. This doesnot imply that the larger numerical has more weightage than the lower nuericals. So it is important to normalize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.43412385, -0.26355339,  1.97020822, ...,  4.04411161,\n",
       "         1.87082869,  4.11438171],\n",
       "       [ 1.79820852, -0.19167519,  3.21455025, ..., -0.31108551,\n",
       "        -0.53452248, -0.27299215],\n",
       "       [-0.30511119, -0.26355339,  0.72586619, ..., -0.31108551,\n",
       "        -0.53452248, -0.27299215],\n",
       "       ...,\n",
       "       [-0.42196229, -0.26355339, -0.51847585, ..., -0.31108551,\n",
       "         1.87082869, -0.27299215],\n",
       "       [-0.42196229, -0.26355339, -0.51847585, ..., -0.31108551,\n",
       "        -0.53452248, -0.27299215],\n",
       "       [-0.42196229, -0.19167519,  0.10369517, ...,  0.31108551,\n",
       "        -0.53452248, -0.27299215]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 678)\n",
      "(1, 678)\n",
      "(18, 61)\n",
      "(1, 61)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693147\n",
      "Cost after iteration 100: 0.207322\n",
      "Cost after iteration 200: 0.049913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karti\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 300: 0.045651\n",
      "Cost after iteration 400: 0.025756\n",
      "Cost after iteration 500: 0.024978\n",
      "Cost after iteration 600: 0.024168\n",
      "Cost after iteration 700: 0.025388\n",
      "Cost after iteration 800: 0.014550\n",
      "Cost after iteration 900: 0.014119\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters, A_hat = Spam_model(X_train, Y_train, node_vector = [18,10, 5,2, 1], num_iterations = 1000, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(A_hat, Y):\n",
    "    count = 0\n",
    "    for i in range (len(A_hat)):\n",
    "        if A_hat[:,i] == Y[:,i]:\n",
    "            count = count + 1\n",
    "    pred = (count / len(Y))*100\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_hat_test, cache = forward_propogation(parameters, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_hat_pred = np.round(A_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 61)\n",
      "(1, 61)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
       "        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "        0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 946,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(A_hat_pred.shape)\n",
    "print(Y_test.shape)\n",
    "A_hat_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "        1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "        1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 947,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = A_hat_pred - Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at the test set is100.0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for y in final_pred:\n",
    "    for x in y:\n",
    "        if x == 1:\n",
    "            count += 1\n",
    "\n",
    "accuracy = count / 61\n",
    "print(f\"Accuracy at the test set is{(1 - accuracy)*100}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras library\n",
    "\n",
    "Now i am Re-implementing my model using the Keras library. Where I donot need to code again and again for forward or back propogation or for weights of the matrix or for the activation rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Hidden and Input layer\n",
    "\n",
    "I am adding the 1st hidden and the input layer in the model using just one line of code of keras. The output_dim correspond to the number of nodes in the 1st hidden layer and the input_dim corresponds to the nodes in the input layer. While INIT means that the weight matrix will be initialized uniformily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karti\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=18, units=6, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 18) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Hidden Layer\n",
    "\n",
    "Now we are adding the 2nd Hidden layer. For this we just need to mention the nodes of 2nd hidden layer(6) in it in the output_dim. NOTE: that there is no need to mention the Input_dims as we have already know that the previous layer has 6 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karti\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output layer (Sigmoid Func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karti\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1 , random_state = 0) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could have use categorical_crossentropy in the lost only if the output layer has many nodes like in softmax\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.T\n",
    "Y_train = Y_train.T\n",
    "X_test = X_test.T\n",
    "Y_test = Y_test.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "678/678 [==============================] - 0s 159us/step - loss: 0.6913 - accuracy: 0.6224\n",
      "Epoch 2/200\n",
      "678/678 [==============================] - 0s 44us/step - loss: 0.6869 - accuracy: 0.6401\n",
      "Epoch 3/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.6780 - accuracy: 0.6401\n",
      "Epoch 4/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.6612 - accuracy: 0.6401\n",
      "Epoch 5/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.6299 - accuracy: 0.6549\n",
      "Epoch 6/200\n",
      "678/678 [==============================] - 0s 44us/step - loss: 0.5843 - accuracy: 0.7139\n",
      "Epoch 7/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.5271 - accuracy: 0.8142\n",
      "Epoch 8/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.4677 - accuracy: 0.8348\n",
      "Epoch 9/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.4102 - accuracy: 0.8894\n",
      "Epoch 10/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.3589 - accuracy: 0.9071\n",
      "Epoch 11/200\n",
      "678/678 [==============================] - 0s 44us/step - loss: 0.3158 - accuracy: 0.9351\n",
      "Epoch 12/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.2804 - accuracy: 0.9351\n",
      "Epoch 13/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.2500 - accuracy: 0.9454\n",
      "Epoch 14/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.2277 - accuracy: 0.9602\n",
      "Epoch 15/200\n",
      "678/678 [==============================] - 0s 46us/step - loss: 0.2039 - accuracy: 0.9676\n",
      "Epoch 16/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.1861 - accuracy: 0.9661\n",
      "Epoch 17/200\n",
      "678/678 [==============================] - 0s 46us/step - loss: 0.1724 - accuracy: 0.9661\n",
      "Epoch 18/200\n",
      "678/678 [==============================] - 0s 47us/step - loss: 0.1552 - accuracy: 0.9808\n",
      "Epoch 19/200\n",
      "678/678 [==============================] - 0s 37us/step - loss: 0.1446 - accuracy: 0.9779\n",
      "Epoch 20/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.1321 - accuracy: 0.9749\n",
      "Epoch 21/200\n",
      "678/678 [==============================] - 0s 44us/step - loss: 0.1232 - accuracy: 0.9794\n",
      "Epoch 22/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.1145 - accuracy: 0.9808\n",
      "Epoch 23/200\n",
      "678/678 [==============================] - 0s 46us/step - loss: 0.1083 - accuracy: 0.9794\n",
      "Epoch 24/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.1000 - accuracy: 0.9794\n",
      "Epoch 25/200\n",
      "678/678 [==============================] - 0s 54us/step - loss: 0.0940 - accuracy: 0.9808\n",
      "Epoch 26/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0880 - accuracy: 0.9853\n",
      "Epoch 27/200\n",
      "678/678 [==============================] - 0s 46us/step - loss: 0.0829 - accuracy: 0.9838\n",
      "Epoch 28/200\n",
      "678/678 [==============================] - 0s 44us/step - loss: 0.0784 - accuracy: 0.9838\n",
      "Epoch 29/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0749 - accuracy: 0.9823\n",
      "Epoch 30/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0719 - accuracy: 0.9853\n",
      "Epoch 31/200\n",
      "678/678 [==============================] - 0s 47us/step - loss: 0.0702 - accuracy: 0.9838\n",
      "Epoch 32/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.0654 - accuracy: 0.9838\n",
      "Epoch 33/200\n",
      "678/678 [==============================] - 0s 35us/step - loss: 0.0618 - accuracy: 0.9867\n",
      "Epoch 34/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0587 - accuracy: 0.9882\n",
      "Epoch 35/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.0560 - accuracy: 0.9853\n",
      "Epoch 36/200\n",
      "678/678 [==============================] - 0s 46us/step - loss: 0.0538 - accuracy: 0.9867\n",
      "Epoch 37/200\n",
      "678/678 [==============================] - 0s 46us/step - loss: 0.0516 - accuracy: 0.9867\n",
      "Epoch 38/200\n",
      "678/678 [==============================] - 0s 37us/step - loss: 0.0507 - accuracy: 0.9897\n",
      "Epoch 39/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0496 - accuracy: 0.9897\n",
      "Epoch 40/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.0477 - accuracy: 0.9867\n",
      "Epoch 41/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0459 - accuracy: 0.9882\n",
      "Epoch 42/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0453 - accuracy: 0.9867\n",
      "Epoch 43/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0425 - accuracy: 0.9882\n",
      "Epoch 44/200\n",
      "678/678 [==============================] - 0s 46us/step - loss: 0.0406 - accuracy: 0.9882\n",
      "Epoch 45/200\n",
      "678/678 [==============================] - 0s 47us/step - loss: 0.0400 - accuracy: 0.9882\n",
      "Epoch 46/200\n",
      "678/678 [==============================] - 0s 47us/step - loss: 0.0397 - accuracy: 0.9912\n",
      "Epoch 47/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0370 - accuracy: 0.9912\n",
      "Epoch 48/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0381 - accuracy: 0.9882\n",
      "Epoch 49/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0364 - accuracy: 0.9897\n",
      "Epoch 50/200\n",
      "678/678 [==============================] - 0s 49us/step - loss: 0.0356 - accuracy: 0.9897\n",
      "Epoch 51/200\n",
      "678/678 [==============================] - 0s 47us/step - loss: 0.0346 - accuracy: 0.9912\n",
      "Epoch 52/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0328 - accuracy: 0.9912\n",
      "Epoch 53/200\n",
      "678/678 [==============================] - 0s 44us/step - loss: 0.0330 - accuracy: 0.9897\n",
      "Epoch 54/200\n",
      "678/678 [==============================] - 0s 44us/step - loss: 0.0311 - accuracy: 0.9912\n",
      "Epoch 55/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.0315 - accuracy: 0.9882\n",
      "Epoch 56/200\n",
      "678/678 [==============================] - 0s 47us/step - loss: 0.0287 - accuracy: 0.9912\n",
      "Epoch 57/200\n",
      "678/678 [==============================] - 0s 37us/step - loss: 0.0293 - accuracy: 0.9926\n",
      "Epoch 58/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0283 - accuracy: 0.9897\n",
      "Epoch 59/200\n",
      "678/678 [==============================] - 0s 44us/step - loss: 0.0280 - accuracy: 0.9912\n",
      "Epoch 60/200\n",
      "678/678 [==============================] - 0s 37us/step - loss: 0.0278 - accuracy: 0.9912\n",
      "Epoch 61/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0265 - accuracy: 0.9926\n",
      "Epoch 62/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0255 - accuracy: 0.9912\n",
      "Epoch 63/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0245 - accuracy: 0.9912\n",
      "Epoch 64/200\n",
      "678/678 [==============================] - 0s 32us/step - loss: 0.0241 - accuracy: 0.9926\n",
      "Epoch 65/200\n",
      "678/678 [==============================] - 0s 35us/step - loss: 0.0266 - accuracy: 0.9897\n",
      "Epoch 66/200\n",
      "678/678 [==============================] - 0s 37us/step - loss: 0.0234 - accuracy: 0.9912\n",
      "Epoch 67/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.0227 - accuracy: 0.9926\n",
      "Epoch 68/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0222 - accuracy: 0.9912\n",
      "Epoch 69/200\n",
      "678/678 [==============================] - 0s 37us/step - loss: 0.0223 - accuracy: 0.9926\n",
      "Epoch 70/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0220 - accuracy: 0.9941\n",
      "Epoch 71/200\n",
      "678/678 [==============================] - 0s 37us/step - loss: 0.0216 - accuracy: 0.9912\n",
      "Epoch 72/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0212 - accuracy: 0.9926\n",
      "Epoch 73/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0209 - accuracy: 0.9926\n",
      "Epoch 74/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0204 - accuracy: 0.9926\n",
      "Epoch 75/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0211 - accuracy: 0.9912\n",
      "Epoch 76/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0197 - accuracy: 0.9926\n",
      "Epoch 77/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0196 - accuracy: 0.9926\n",
      "Epoch 78/200\n",
      "678/678 [==============================] - 0s 44us/step - loss: 0.0183 - accuracy: 0.9926\n",
      "Epoch 79/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0189 - accuracy: 0.9926\n",
      "Epoch 80/200\n",
      "678/678 [==============================] - 0s 37us/step - loss: 0.0182 - accuracy: 0.9941\n",
      "Epoch 81/200\n",
      "678/678 [==============================] - 0s 44us/step - loss: 0.0173 - accuracy: 0.9926\n",
      "Epoch 82/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0180 - accuracy: 0.9941\n",
      "Epoch 83/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0176 - accuracy: 0.9941\n",
      "Epoch 84/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0195 - accuracy: 0.9941\n",
      "Epoch 85/200\n",
      "678/678 [==============================] - 0s 37us/step - loss: 0.0172 - accuracy: 0.9926\n",
      "Epoch 86/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0176 - accuracy: 0.9956\n",
      "Epoch 87/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0163 - accuracy: 0.9941\n",
      "Epoch 88/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0162 - accuracy: 0.9941\n",
      "Epoch 89/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0157 - accuracy: 0.9956\n",
      "Epoch 90/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0154 - accuracy: 0.9956\n",
      "Epoch 91/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0152 - accuracy: 0.9956\n",
      "Epoch 92/200\n",
      "678/678 [==============================] - 0s 37us/step - loss: 0.0150 - accuracy: 0.9956\n",
      "Epoch 93/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0155 - accuracy: 0.9956\n",
      "Epoch 94/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0168 - accuracy: 0.9941\n",
      "Epoch 95/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0138 - accuracy: 0.9971\n",
      "Epoch 96/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0148 - accuracy: 0.9941\n",
      "Epoch 97/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0139 - accuracy: 0.9956\n",
      "Epoch 98/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0145 - accuracy: 0.9926\n",
      "Epoch 99/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0144 - accuracy: 0.9956\n",
      "Epoch 100/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0131 - accuracy: 0.9956\n",
      "Epoch 101/200\n",
      "678/678 [==============================] - 0s 37us/step - loss: 0.0137 - accuracy: 0.9941\n",
      "Epoch 102/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0141 - accuracy: 0.9956\n",
      "Epoch 104/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0127 - accuracy: 0.9971\n",
      "Epoch 105/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0128 - accuracy: 0.9956\n",
      "Epoch 106/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0124 - accuracy: 0.9971\n",
      "Epoch 107/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0121 - accuracy: 0.9971\n",
      "Epoch 108/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0122 - accuracy: 0.9985\n",
      "Epoch 109/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0121 - accuracy: 0.9956\n",
      "Epoch 110/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0119 - accuracy: 0.9971\n",
      "Epoch 111/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0114 - accuracy: 0.9956\n",
      "Epoch 112/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0126 - accuracy: 0.9956\n",
      "Epoch 113/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0121 - accuracy: 0.9971\n",
      "Epoch 114/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0112 - accuracy: 0.9985\n",
      "Epoch 115/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0112 - accuracy: 0.9956\n",
      "Epoch 116/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0107 - accuracy: 0.9985\n",
      "Epoch 117/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0106 - accuracy: 0.9971\n",
      "Epoch 118/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0107 - accuracy: 0.9971\n",
      "Epoch 119/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0112 - accuracy: 0.9971\n",
      "Epoch 120/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0108 - accuracy: 0.9956\n",
      "Epoch 121/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0104 - accuracy: 0.9971\n",
      "Epoch 122/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0101 - accuracy: 0.9971\n",
      "Epoch 123/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.0104 - accuracy: 0.9956\n",
      "Epoch 124/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0100 - accuracy: 0.9985\n",
      "Epoch 125/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0097 - accuracy: 0.9971\n",
      "Epoch 126/200\n",
      "678/678 [==============================] - 0s 44us/step - loss: 0.0097 - accuracy: 0.9971\n",
      "Epoch 127/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.0102 - accuracy: 0.9985\n",
      "Epoch 128/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0097 - accuracy: 0.9985\n",
      "Epoch 129/200\n",
      "678/678 [==============================] - 0s 37us/step - loss: 0.0109 - accuracy: 0.9971\n",
      "Epoch 130/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0110 - accuracy: 0.9985\n",
      "Epoch 131/200\n",
      "678/678 [==============================] - 0s 37us/step - loss: 0.0091 - accuracy: 0.9971\n",
      "Epoch 132/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0091 - accuracy: 0.9971\n",
      "Epoch 133/200\n",
      "678/678 [==============================] - 0s 46us/step - loss: 0.0091 - accuracy: 0.9971\n",
      "Epoch 134/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.0094 - accuracy: 0.9971\n",
      "Epoch 135/200\n",
      "678/678 [==============================] - 0s 35us/step - loss: 0.0090 - accuracy: 0.9985\n",
      "Epoch 136/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.0090 - accuracy: 0.9956\n",
      "Epoch 137/200\n",
      "678/678 [==============================] - 0s 44us/step - loss: 0.0092 - accuracy: 0.9985\n",
      "Epoch 138/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0094 - accuracy: 0.9956\n",
      "Epoch 140/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0103 - accuracy: 0.9971\n",
      "Epoch 141/200\n",
      "678/678 [==============================] - 0s 44us/step - loss: 0.0090 - accuracy: 0.9971\n",
      "Epoch 142/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.0079 - accuracy: 0.9971\n",
      "Epoch 143/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0081 - accuracy: 0.9985\n",
      "Epoch 144/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0078 - accuracy: 0.9985\n",
      "Epoch 145/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.0088 - accuracy: 0.9985\n",
      "Epoch 146/200\n",
      "678/678 [==============================] - 0s 46us/step - loss: 0.0083 - accuracy: 0.9956\n",
      "Epoch 147/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0091 - accuracy: 0.9985\n",
      "Epoch 148/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0088 - accuracy: 0.9971\n",
      "Epoch 149/200\n",
      "678/678 [==============================] - 0s 46us/step - loss: 0.0087 - accuracy: 0.9971\n",
      "Epoch 150/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.0071 - accuracy: 0.9985\n",
      "Epoch 151/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.0073 - accuracy: 0.9985\n",
      "Epoch 152/200\n",
      "678/678 [==============================] - 0s 37us/step - loss: 0.0075 - accuracy: 0.9985\n",
      "Epoch 153/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.0077 - accuracy: 0.9971\n",
      "Epoch 154/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0075 - accuracy: 0.9971\n",
      "Epoch 156/200\n",
      "678/678 [==============================] - 0s 81us/step - loss: 0.0076 - accuracy: 0.9985\n",
      "Epoch 157/200\n",
      "678/678 [==============================] - 0s 50us/step - loss: 0.0071 - accuracy: 0.9985\n",
      "Epoch 158/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0078 - accuracy: 0.9971\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678/678 [==============================] - 0s 38us/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "678/678 [==============================] - 0s 46us/step - loss: 0.0082 - accuracy: 0.9971\n",
      "Epoch 161/200\n",
      "678/678 [==============================] - 0s 49us/step - loss: 0.0075 - accuracy: 0.9971\n",
      "Epoch 162/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0071 - accuracy: 0.9971\n",
      "Epoch 163/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0070 - accuracy: 0.9985\n",
      "Epoch 164/200\n",
      "678/678 [==============================] - 0s 46us/step - loss: 0.0070 - accuracy: 0.9985\n",
      "Epoch 165/200\n",
      "678/678 [==============================] - 0s 46us/step - loss: 0.0072 - accuracy: 0.9985\n",
      "Epoch 166/200\n",
      "678/678 [==============================] - 0s 35us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0069 - accuracy: 0.9985\n",
      "Epoch 168/200\n",
      "678/678 [==============================] - 0s 37us/step - loss: 0.0066 - accuracy: 0.9971\n",
      "Epoch 169/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0069 - accuracy: 0.9971\n",
      "Epoch 170/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "678/678 [==============================] - 0s 37us/step - loss: 0.0063 - accuracy: 0.9971\n",
      "Epoch 172/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0065 - accuracy: 0.9985\n",
      "Epoch 173/200\n",
      "678/678 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.00 - 0s 41us/step - loss: 0.0058 - accuracy: 0.9985\n",
      "Epoch 174/200\n",
      "678/678 [==============================] - 0s 37us/step - loss: 0.0066 - accuracy: 0.9985\n",
      "Epoch 175/200\n",
      "678/678 [==============================] - 0s 44us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.0063 - accuracy: 0.9985\n",
      "Epoch 177/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "678/678 [==============================] - 0s 37us/step - loss: 0.0063 - accuracy: 0.9985\n",
      "Epoch 179/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0065 - accuracy: 0.9985\n",
      "Epoch 180/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.0054 - accuracy: 0.9985\n",
      "Epoch 181/200\n",
      "678/678 [==============================] - 0s 37us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0079 - accuracy: 0.9971\n",
      "Epoch 183/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0064 - accuracy: 0.9971\n",
      "Epoch 184/200\n",
      "678/678 [==============================] - 0s 35us/step - loss: 0.0055 - accuracy: 0.9985\n",
      "Epoch 185/200\n",
      "678/678 [==============================] - 0s 47us/step - loss: 0.0055 - accuracy: 0.9985\n",
      "Epoch 186/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.0055 - accuracy: 0.9985\n",
      "Epoch 187/200\n",
      "678/678 [==============================] - 0s 44us/step - loss: 0.0060 - accuracy: 0.9985\n",
      "Epoch 188/200\n",
      "678/678 [==============================] - 0s 46us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0058 - accuracy: 0.9985\n",
      "Epoch 190/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0059 - accuracy: 0.9971\n",
      "Epoch 191/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.0057 - accuracy: 0.9985\n",
      "Epoch 192/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0056 - accuracy: 0.9985\n",
      "Epoch 193/200\n",
      "678/678 [==============================] - 0s 43us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "678/678 [==============================] - 0s 38us/step - loss: 0.0058 - accuracy: 0.9971\n",
      "Epoch 195/200\n",
      "678/678 [==============================] - 0s 46us/step - loss: 0.0056 - accuracy: 0.9985\n",
      "Epoch 196/200\n",
      "678/678 [==============================] - 0s 46us/step - loss: 0.0105 - accuracy: 0.9956\n",
      "Epoch 197/200\n",
      "678/678 [==============================] - 0s 37us/step - loss: 0.0073 - accuracy: 0.9985\n",
      "Epoch 198/200\n",
      "678/678 [==============================] - 0s 40us/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "678/678 [==============================] - 0s 35us/step - loss: 0.0057 - accuracy: 0.9971\n",
      "Epoch 200/200\n",
      "678/678 [==============================] - 0s 41us/step - loss: 0.0056 - accuracy: 0.9985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b40aac36c8>"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, Y_train, batch_size = 20, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred =  classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(Y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Y_test - y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ata the test set is\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "for num in result:\n",
    "    if num == 0:\n",
    "        t += 1\n",
    "print (\"Accuracy ata the test set is\")        \n",
    "print(t/len(Y_test)*100)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
